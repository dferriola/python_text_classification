{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.feature_extraction.text as ext\n",
    "categories = ['talk.politics.misc', 'soc.religion.christian',\n",
    "               'talk.politics.mideast', 'sci.med', 'sci.space',\n",
    "              'sci.electronics', 'talk.politics.misc']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3406, 48556)\n"
     ]
    }
   ],
   "source": [
    "#bag of words will use numbers to represent words and\n",
    "#aspects about them like location.\n",
    "#By simplying the text information it is easier\n",
    "#to analyze and extract information about it.\n",
    "#below is gathering the dataset and creating a bag of words\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                  categories=categories, \n",
    "                                  shuffle=True, \n",
    "                                  random_state=42)\n",
    "#twenty_train is a bunch and bag of words process occurs\n",
    "#by giving a value to every word in the training set.\n",
    "#Then it will count every occurence of the words.\n",
    "count_vect = ext.CountVectorizer()\n",
    "X_train_count = count_vect.fit_transform(\n",
    "    twenty_train.data)\n",
    "#The result will be placed in X_train_count\n",
    "print X_train_counts.shape #shape shows the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.politics.misc']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n-grams with the n referring to the size. The items can\n",
    "#be letters, syllables, words and pairs. The purpose of an\n",
    "#n-gram is to predict the next sequence in a series\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.feature_extraction.text as ext\n",
    "categories=[\"sci.med\"]\n",
    "med_train = fetch_20newsgroups(subset='train',\n",
    "                                  categories=categories,\n",
    "                                  remove=('headers','footers','quotes'),\n",
    "                                  shuffle=True, \n",
    "                                  random_state=42)\n",
    "count_chars= ext.CountVectorizer(analyzer='char_wb',\n",
    "        ngram_range=(3,3),max_features=10).fit(med_train['data'])\n",
    "count_words= ext.CountVectorizer(analyzer='word',\n",
    "        ngram_range=(2,2),max_features=10,\n",
    "                                stop_words='english').fit(med_train['data'])\n",
    "X = count_chars.transform(med_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'banks n3jxp', u'cadre dsl', u'chastity intellect', u'dsl pitt', u'geb cadre', u'gordon banks', u'intellect geb', u'n3jxp skepticism', u'pitt edu', u'skepticism chastity']\n"
     ]
    }
   ],
   "source": [
    "print count_words.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 9 4 0 3 3 1 5]]\n"
     ]
    }
   ],
   "source": [
    "print X[1].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'banks n3jxp', u'cadre dsl', u'chastity intellect', u'dsl pitt', u'geb cadre', u'gordon banks', u'intellect geb', u'n3jxp skepticism', u'pitt edu', u'skepticism chastity']\n"
     ]
    }
   ],
   "source": [
    "print count_words.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3406"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lundby@rtsg.mot.com (Walter F. Lundby)\n",
      "Subject: Re: Is MSG sensitivity superstition?\n",
      "Nntp-Posting-Host: accord2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 5, 3, 5, 0, 1, 3, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.med\n",
      "sci.electronics\n",
      "sci.space\n",
      "talk.politics.misc\n",
      "soc.religion.christian\n",
      "talk.politics.misc\n",
      "sci.electronics\n",
      "sci.med\n",
      "soc.religion.christian\n",
      "sci.electronics\n"
     ]
    }
   ],
   "source": [
    "#names of categories\n",
    "for t in twenty_train.target[:10]:\n",
    "     print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3406, 48556)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another example of bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect= CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6892"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3406, 48556)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3406, 48556)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'war' => talk.politics.mideast\n",
      "'moon' => sci.space\n",
      "'diabetes' => sci.med\n",
      "'stable' => sci.space\n",
      "'terrible' => soc.religion.christian\n",
      "'life' => soc.religion.christian\n",
      "'death' => soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "#training a classifier\n",
    "docs_new = ['war', 'moon', 'diabetes','stable','terrible','life','death']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MultinomialNB()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84252315835906488"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating accuracy\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "     categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92148213498014997"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, random_state=42,\n",
    "                                            max_iter=5, tol=None)),\n",
    "])\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "report =metrics.classification_report(twenty_test.target, predicted,\n",
    "     target_names=twenty_test.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]\n",
    "'soc.religion.christian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "...     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['talk.politics.misc',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.mideast',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'sci.electronics',\n",
       " 'talk.politics.misc']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Of course.  The term must be rigidly defined in any bill.\n",
      "\n",
      "\n",
      "I doubt she uses this term for that.  You are using a quote allegedly\n",
      "from her, can you back it up?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I read the article as presenting first an argument about weapons of mass\n",
      "destruction (as commonly understood) and then switching to other topics.\n",
      "The first point evidently was to show that not all weapons should be\n",
      "allowed, and then the later analysis was, given this understanding, to\n",
      "consider another class.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print newsgroups_train.data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://epopt.readthedocs.io/en/latest/notebooks/newsgroups.html\n",
    "from sklearn.feature_extraction import text\n",
    "vectorizer = text.TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(newsgroups_train.data)\n",
    "y = newsgroups_train.target\n",
    "Xtest = vectorizer.transform(newsgroups_test.data)\n",
    "ytest = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 5000)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 18846 samples in 0.039s...\n",
      "[t-SNE] Computed neighbors for 18846 samples in 18.760s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 18846 / 18846\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 89.465012\n",
      "[t-SNE] Error after 1000 iterations: 1.851367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# an example of a tsne model\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#an example of a classification visualization\n",
    "def plot_classification_report(cr, title='Classification report ', with_avg_total=False, cmap=plt.cm.Blues):\n",
    "\n",
    "    lines = cr.split('\\n')\n",
    "\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "    for line in lines[2 : (len(lines) - 3)]:\n",
    "        #print(line)\n",
    "        t = line.split()\n",
    "        # print(t)\n",
    "        classes.append(t[0])\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        print(v)\n",
    "        plotMat.append(v)\n",
    "\n",
    "    if with_avg_total:\n",
    "        aveTotal = lines[len(lines) - 1].split()\n",
    "        classes.append('avg/total')\n",
    "        vAveTotal = [float(x) for x in t[1:len(aveTotal) - 1]]\n",
    "        plotMat.append(vAveTotal)\n",
    "\n",
    "\n",
    "    plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    x_tick_marks = np.arange(3)\n",
    "    y_tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n",
    "    plt.yticks(y_tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87, 0.97, 0.92]\n",
      "[0.94, 0.86, 0.9]\n",
      "[0.94, 0.94, 0.94]\n",
      "[0.93, 0.97, 0.95]\n",
      "[0.95, 0.92, 0.94]\n",
      "[0.91, 0.84, 0.88]\n"
     ]
    }
   ],
   "source": [
    "plot_classification_report(report, with_avg_total=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
